# Linear Regression

## Table of Contents

- [Section 1: Intro to Linear Regression](#section-1-intro-to-linear-regression)
- [Section 2: Least Squared Loss and Maximum Likelihood](#section-2-least-squared-loss-and-maximum-likelihood)
- [Section 3: Ridge Regression](#section-3-ridge-regression)

## Section 1: Intro to Linear Regression

In this section, we will introduce the concept of linear regression, which is a fundamental supervised learning algorithm used for predictive modeling. Linear regression aims to establish a linear relationship between input features and the target variable. We will explore how this simple yet powerful technique can be applied to various real-world datasets.

## Section 2: Least Squared Loss and Maximum Likelihood

Here, we will delve into the mathematics behind linear regression. We'll discuss the two common approaches used for parameter estimation: the least squared loss and the maximum likelihood method.  These concepts will provide insights into how linear regression optimizes the model parameters to best fit the data.


## Section 3: Ridge Regression

Ridge regression is an extension of linear regression that addresses the issue of multicollinearity and can help prevent overfitting. In this section, we will explore the concept of ridge regression and how it introduces a regularization term to the least squared loss, resulting in improved model stability and performance.




