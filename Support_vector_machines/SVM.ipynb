{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Arz0uQUpJ8nx"
   },
   "source": [
    "# Support Vector Machines (SVMs)\n",
    " we will learn a linear and kernalised method of SVMs, which can be used for both regression and classification. To start with, we will focus on binary classification. We will use stochastic gradient descent (SGD) for the optimisation of the hinge loss.\n",
    "\n",
    "We will work with the [Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)\n",
    "<a name=\"section-1\"></a>\n",
    "\n",
    "## Section 1: Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oeRdgi8X2_kD"
   },
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "-9FsQfQ1J4MI",
    "outputId": "1b1b3f72-8270-41ff-e865-8b01201d9b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>925291</td>\n",
       "      <td>B</td>\n",
       "      <td>11.51</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.04105</td>\n",
       "      <td>...</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>925292</td>\n",
       "      <td>B</td>\n",
       "      <td>14.05</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.04304</td>\n",
       "      <td>...</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>925311</td>\n",
       "      <td>B</td>\n",
       "      <td>11.20</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>925622</td>\n",
       "      <td>M</td>\n",
       "      <td>15.22</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.09429</td>\n",
       "      <td>...</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.1700</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>926125</td>\n",
       "      <td>M</td>\n",
       "      <td>20.92</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.14740</td>\n",
       "      <td>...</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "559  925291         B        11.51         23.93           74.52      403.5   \n",
       "560  925292         B        14.05         27.15           91.38      600.4   \n",
       "561  925311         B        11.20         29.37           70.67      386.0   \n",
       "562  925622         M        15.22         30.62          103.40      716.9   \n",
       "563  926125         M        20.92         25.09          143.00     1347.0   \n",
       "564  926424         M        21.56         22.39          142.00     1479.0   \n",
       "565  926682         M        20.13         28.25          131.20     1261.0   \n",
       "566  926954         M        16.60         28.08          108.30      858.1   \n",
       "567  927241         M        20.60         29.33          140.10     1265.0   \n",
       "568   92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "559          0.09261           0.10210         0.11120              0.04105   \n",
       "560          0.09929           0.11260         0.04462              0.04304   \n",
       "561          0.07449           0.03558         0.00000              0.00000   \n",
       "562          0.10480           0.20870         0.25500              0.09429   \n",
       "563          0.10990           0.22360         0.31740              0.14740   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "559  ...          37.16            82.28       474.2           0.12980   \n",
       "560  ...          33.17           100.20       706.7           0.12410   \n",
       "561  ...          38.30            75.19       439.6           0.09267   \n",
       "562  ...          42.79           128.70       915.0           0.14170   \n",
       "563  ...          29.41           179.10      1819.0           0.14070   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "559            0.25170           0.3630               0.09653          0.2112   \n",
       "560            0.22640           0.1326               0.10480          0.2250   \n",
       "561            0.05494           0.0000               0.00000          0.1566   \n",
       "562            0.79170           1.1700               0.23560          0.4089   \n",
       "563            0.41860           0.6599               0.25420          0.2929   \n",
       "564            0.21130           0.4107               0.22160          0.2060   \n",
       "565            0.19220           0.3215               0.16280          0.2572   \n",
       "566            0.30940           0.3403               0.14180          0.2218   \n",
       "567            0.86810           0.9387               0.26500          0.4087   \n",
       "568            0.06444           0.0000               0.00000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "559                  0.08732          NaN  \n",
       "560                  0.08321          NaN  \n",
       "561                  0.05905          NaN  \n",
       "562                  0.14090          NaN  \n",
       "563                  0.09873          NaN  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from google.colab import files\n",
    "#upload = files.upload()\n",
    "data = pd.read_csv('./data.csv')\n",
    "\n",
    "# print shape and last 10 rows\n",
    "print(data.shape)\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74Tw6xk53p20"
   },
   "source": [
    "We can see that our data set has 569 samples and 33 columns. The column `id` can be taken as an index for our pandas dataframe and `diagnosis` is the label (either **M: malignant** or **B: benign**).\n",
    "\n",
    "Let's prepare the data set first of all by (i) cleaning it, (ii) separating label from features, and (iii) splitting it into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "2mbvvJ-Kz2Dk",
    "outputId": "d6f34d64-ac9f-4bec-bdae-94ee80d14f97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926424</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926682</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926954</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927241</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92751</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                       \n",
       "926424         M        21.56         22.39          142.00     1479.0   \n",
       "926682         M        20.13         28.25          131.20     1261.0   \n",
       "926954         M        16.60         28.08          108.30      858.1   \n",
       "927241         M        20.60         29.33          140.10     1265.0   \n",
       "92751          B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "        smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                          \n",
       "926424          0.11100           0.11590         0.24390   \n",
       "926682          0.09780           0.10340         0.14400   \n",
       "926954          0.08455           0.10230         0.09251   \n",
       "927241          0.11780           0.27700         0.35140   \n",
       "92751           0.05263           0.04362         0.00000   \n",
       "\n",
       "        concave points_mean  symmetry_mean  ...  radius_worst  texture_worst  \\\n",
       "id                                          ...                                \n",
       "926424              0.13890         0.1726  ...        25.450          26.40   \n",
       "926682              0.09791         0.1752  ...        23.690          38.25   \n",
       "926954              0.05302         0.1590  ...        18.980          34.12   \n",
       "927241              0.15200         0.2397  ...        25.740          39.42   \n",
       "92751               0.00000         0.1587  ...         9.456          30.37   \n",
       "\n",
       "        perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                         \n",
       "926424           166.10      2027.0           0.14100            0.21130   \n",
       "926682           155.00      1731.0           0.11660            0.19220   \n",
       "926954           126.70      1124.0           0.11390            0.30940   \n",
       "927241           184.60      1821.0           0.16500            0.86810   \n",
       "92751             59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "        concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                              \n",
       "926424           0.4107                0.2216          0.2060   \n",
       "926682           0.3215                0.1628          0.2572   \n",
       "926954           0.3403                0.1418          0.2218   \n",
       "927241           0.9387                0.2650          0.4087   \n",
       "92751            0.0000                0.0000          0.2871   \n",
       "\n",
       "        fractal_dimension_worst  \n",
       "id                               \n",
       "926424                  0.07115  \n",
       "926682                  0.06637  \n",
       "926954                  0.07820  \n",
       "927241                  0.12400  \n",
       "92751                   0.07039  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop last column (extra column added by pd)\n",
    "data_1 = data.drop(data.columns[-1], axis=1)\n",
    "\n",
    "# set column id as dataframe index\n",
    "data_2 = data_1.set_index(data['id']).drop(data_1.columns[0], axis=1)\n",
    "\n",
    "# check\n",
    "data_2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zQ1tedL7dNI"
   },
   "source": [
    "We do a bit more preparation by converting the categorical labels into 1 for **M** and -1 for **B**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "1zbSOnY06rwL",
    "outputId": "bf349f7a-4c6a-4473-e51e-96f054c07f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "926424    1.0\n",
      "926682    1.0\n",
      "926954    1.0\n",
      "927241    1.0\n",
      "92751    -1.0\n",
      "Name: diagnosis, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926424</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926682</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926954</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927241</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92751</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "id                                                                              \n",
       "926424        21.56         22.39          142.00     1479.0          0.11100   \n",
       "926682        20.13         28.25          131.20     1261.0          0.09780   \n",
       "926954        16.60         28.08          108.30      858.1          0.08455   \n",
       "927241        20.60         29.33          140.10     1265.0          0.11780   \n",
       "92751          7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "        compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "id                                                                             \n",
       "926424           0.11590         0.24390              0.13890         0.1726   \n",
       "926682           0.10340         0.14400              0.09791         0.1752   \n",
       "926954           0.10230         0.09251              0.05302         0.1590   \n",
       "927241           0.27700         0.35140              0.15200         0.2397   \n",
       "92751            0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "        fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "id                              ...                                \n",
       "926424                 0.05623  ...        25.450          26.40   \n",
       "926682                 0.05533  ...        23.690          38.25   \n",
       "926954                 0.05648  ...        18.980          34.12   \n",
       "927241                 0.07016  ...        25.740          39.42   \n",
       "92751                  0.05884  ...         9.456          30.37   \n",
       "\n",
       "        perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                         \n",
       "926424           166.10      2027.0           0.14100            0.21130   \n",
       "926682           155.00      1731.0           0.11660            0.19220   \n",
       "926954           126.70      1124.0           0.11390            0.30940   \n",
       "927241           184.60      1821.0           0.16500            0.86810   \n",
       "92751             59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "        concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                              \n",
       "926424           0.4107                0.2216          0.2060   \n",
       "926682           0.3215                0.1628          0.2572   \n",
       "926954           0.3403                0.1418          0.2218   \n",
       "927241           0.9387                0.2650          0.4087   \n",
       "92751            0.0000                0.0000          0.2871   \n",
       "\n",
       "        fractal_dimension_worst  \n",
       "id                               \n",
       "926424                  0.07115  \n",
       "926682                  0.06637  \n",
       "926954                  0.07820  \n",
       "927241                  0.12400  \n",
       "92751                   0.07039  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical labels to numbers\n",
    "diag_map = {'M': 1.0, 'B': -1.0}\n",
    "data_2['diagnosis'] = data_2['diagnosis'].map(diag_map)\n",
    "\n",
    "# put labels and features in different dataframes\n",
    "y = data_2.loc[:, 'diagnosis']\n",
    "X = data_2.iloc[:, 1:]\n",
    "\n",
    "# check\n",
    "print(y.tail())\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbllXkPK8fQw"
   },
   "source": [
    "As with any data set that has features over different ranges, it's required to standardise the data before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PSVn27p88EFl"
   },
   "outputs": [],
   "source": [
    "\n",
    "def standardise(X):\n",
    "  mu = np.mean(X, 0)\n",
    "  sigma = np.std(X, 0)\n",
    "  X_std = (X - mu) / sigma\n",
    "  return X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "fMyxlg678EC7",
    "outputId": "23f920ae-7dc5-4734-81e6-113155f776c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926424</th>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>-0.312589</td>\n",
       "      <td>-0.931027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901185</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926682</th>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>-0.217664</td>\n",
       "      <td>-1.058611</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536720</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926954</th>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>-0.809117</td>\n",
       "      <td>-0.895587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927241</th>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>2.137194</td>\n",
       "      <td>1.043695</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961239</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92751</th>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>-0.820070</td>\n",
       "      <td>-0.561032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410893</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "id                                                                              \n",
       "926424     2.110995      0.721473        2.060786   2.343856         1.041842   \n",
       "926682     1.704854      2.085134        1.615931   1.723842         0.102458   \n",
       "926954     0.702284      2.045574        0.672676   0.577953        -0.840484   \n",
       "927241     1.838341      2.336457        1.982524   1.735218         1.525767   \n",
       "92751     -1.808401      1.221792       -1.814389  -1.347789        -3.112085   \n",
       "\n",
       "        compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "id                                                                             \n",
       "926424          0.219060        1.947285             2.320965      -0.312589   \n",
       "926682         -0.017833        0.693043             1.263669      -0.217664   \n",
       "926954         -0.038680        0.046588             0.105777      -0.809117   \n",
       "927241          3.272144        3.296944             2.658866       2.137194   \n",
       "92751          -1.150752       -1.114873            -1.261820      -0.820070   \n",
       "\n",
       "        fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "id                              ...                                \n",
       "926424               -0.931027  ...      1.901185       0.117700   \n",
       "926682               -1.058611  ...      1.536720       2.047399   \n",
       "926954               -0.895587  ...      0.561361       1.374854   \n",
       "927241                1.043695  ...      1.961239       2.237926   \n",
       "92751                -0.561032  ...     -1.410893       0.764190   \n",
       "\n",
       "        perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                         \n",
       "926424         1.752563    2.015301          0.378365          -0.273318   \n",
       "926682         1.421940    1.494959         -0.691230          -0.394820   \n",
       "926954         0.579001    0.427906         -0.809587           0.350735   \n",
       "927241         2.303601    1.653171          1.430427           3.904848   \n",
       "92751         -1.432735   -1.075813         -1.859019          -1.207552   \n",
       "\n",
       "        concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                              \n",
       "926424         0.664512              1.629151       -1.360158   \n",
       "926682         0.236573              0.733827       -0.531855   \n",
       "926954         0.326767              0.414069       -1.104549   \n",
       "927241         3.197605              2.289985        1.919083   \n",
       "92751         -1.305831             -1.745063       -0.048138   \n",
       "\n",
       "        fractal_dimension_worst  \n",
       "id                               \n",
       "926424                -0.709091  \n",
       "926682                -0.973978  \n",
       "926954                -0.318409  \n",
       "927241                 2.219635  \n",
       "92751                 -0.751207  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = standardise(X)\n",
    "\n",
    "# check\n",
    "X_std.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qcw02XXM8EAe",
    "outputId": "3a86181e-1e1d-45c6-fc72-5187bc3c459c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\44746\\AppData\\Local\\Temp\\ipykernel_29712\\73579034.py:3: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  data_split = np.hstack((X_std, y[:, np.newaxis]))\n"
     ]
    }
   ],
   "source": [
    "# split into train and test set\n",
    "# stacking data X and labels y into one matrix\n",
    "data_split = np.hstack((X_std, y[:, np.newaxis]))\n",
    "\n",
    "# shuffling the rows        \n",
    "np.random.shuffle(data_split)\n",
    "\n",
    "# we split train to test as 70:30\n",
    "split_rate = 0.7\n",
    "train, test = np.split(data_split, [int(split_rate*(data_split.shape[0]))])\n",
    "\n",
    "X_train = train[:,:-1]\n",
    "y_train = train[:, -1]\n",
    "\n",
    "X_test = test[:,:-1]\n",
    "y_test = test[:, -1]\n",
    "\n",
    "y_train = y_train.astype(float)\n",
    "y_test = y_test.astype(float)\n",
    "\n",
    "# insert 1 in every row for intercept b\n",
    "X_train_intercept = np.hstack((X_train, np.ones((len(X_train),1)) ))\n",
    "X_test_intercept = np.hstack((X_test, np.ones((len(X_test),1)) ))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMo_v3TGCJBD",
    "tags": []
   },
   "source": [
    "<a name=\"section-2\"></a>\n",
    "\n",
    "## Section 2: Linear SVM Formulation\n",
    "\n",
    "We start with defining the hinge loss as\n",
    "$$\n",
    "\\mathcal L (\\boldsymbol w) = \\frac{1}{2} \\| \\boldsymbol w \\|^2 + \\lambda \\sum_{i=1}^n \\max \\bigg( 0, 1-y_i (x^{(i)} \\cdot \\boldsymbol w  + b) \\bigg) \\, .\n",
    "$$\n",
    "where $\\boldsymbol w$ is the vector of weights, $\\lambda$ the regularisation parameter, and $b$ the intercept which is included in our `X` as an additional column of $1$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O8NCZ2Wj8D8m"
   },
   "outputs": [],
   "source": [
    "def compute_cost(w, X, y, regul_strength=1e5):\n",
    "  n = X.shape[0]\n",
    "  distances = 1 - y * (X @ w)\n",
    "  distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "  hinge = regul_strength * distances.mean()\n",
    "    \n",
    "  # calculate cost\n",
    "  return 0.5 * np.dot(w, w) + hinge -0.5*w[-1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bm_NG7EfAYfr"
   },
   "source": [
    "<a name=\"section-3\"></a>\n",
    "\n",
    "## Section 3: SVM Optimization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPlQQlNJHgGI"
   },
   "source": [
    "One way to optimize the cost is by using stochastic gradient descent (SGD) algorithm. In order to use SGD, we need to implement a function for the cost gradients with respect to $\\boldsymbol w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yvsu7ukAE79Y"
   },
   "outputs": [],
   "source": [
    "# calculate gradient of cost\n",
    "def calculate_cost_gradient(w, X_batch, y_batch, regul_strength=1e6):\n",
    "  # if only one example is passed\n",
    "  if type(y_batch) == np.float64:\n",
    "      y_batch = np.asarray([y_batch])\n",
    "      X_batch = np.asarray([X_batch])  # gives multidimensional array\n",
    "\n",
    "  distance = 1 - (y_batch * (X_batch @ w))\n",
    "  dw = np.zeros(len(w))\n",
    "  \n",
    "  we = w.copy() # So as not to overwrite w\n",
    "  we[-1] = 0 # So as not to have b in its derivative when adding the weights in di\n",
    "    \n",
    "  for ind, d in enumerate(distance):\n",
    "      if max(0, d)==0:\n",
    "          di = we # derivative of first term\n",
    "      else:\n",
    "          di = we - (regul_strength * y_batch[ind] * X_batch[ind])\n",
    "      dw += di\n",
    "\n",
    "  return dw/len(y_batch)  # average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5X3_B9V-I0mX"
   },
   "source": [
    "Both of the two previous functions are then used in SGD to update the weights iteratively with a given learning rate $\\alpha$. We also implement a stop criterion that ends the learning as soon as the cost function has not changed more than a manually determined percentage.\n",
    "\n",
    "We know that the learning happens through updating the weights according to\n",
    "$$\n",
    "\\boldsymbol w = \\boldsymbol w - \\alpha \\frac{\\partial \\mathcal L}{\\partial \\boldsymbol w}\n",
    "$$\n",
    "\n",
    "where $\\frac{\\partial \\mathcal L}{\\partial \\boldsymbol w}$ is the gradient of the hinge loss we have computed in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a-S8N9C78D5R"
   },
   "outputs": [],
   "source": [
    "def sgd(X, y, max_iterations=2000, stop_criterion=0.01, learning_rate=1e-5, regul_strength=1e6, print_outcome=False):\n",
    "  \n",
    "  # initialise zero weights\n",
    "  weights = np.zeros(X.shape[1])\n",
    "  nth = 0\n",
    "  # initialise starting cost as infinity\n",
    "  prev_cost = np.inf\n",
    "  \n",
    "  # stochastic gradient descent\n",
    "  indices = np.arange(len(y))\n",
    "\n",
    "  for iteration in range(1, max_iterations):\n",
    "    # shuffle to prevent repeating update cycles\n",
    "    np.random.shuffle(indices)\n",
    "    X, y = X[indices], y[indices]\n",
    "    \n",
    "    for xi, yi in zip(X, y):\n",
    "      descent = calculate_cost_gradient(weights, xi, yi, regul_strength)\n",
    "      weights = weights - (learning_rate * descent)\n",
    "\n",
    "    # convergence check on 2^n'th iteration\n",
    "    if iteration==2**nth or iteration==max_iterations-1:\n",
    "      # compute cost\n",
    "      cost = compute_cost(weights, X, y, regul_strength) \n",
    "      if print_outcome:\n",
    "        print(\"Iteration is: {}, Cost is: {}\".format(iteration, cost))\n",
    "      # stop criterion\n",
    "      if abs(prev_cost - cost) < stop_criterion * prev_cost:\n",
    "        return weights\n",
    "        \n",
    "      prev_cost = cost\n",
    "      nth += 1\n",
    "  \n",
    "  return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTU9fyVYK8ay"
   },
   "source": [
    "Now, we can take these functions and train a linear SVM with our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bdsUvtu8D2f",
    "outputId": "197ed763-5f23-4ef6-999d-5998cbecd94d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration is: 1, Cost is: 6.9907420010698305\n",
      "Iteration is: 2, Cost is: 4.854995029501536\n",
      "Iteration is: 4, Cost is: 3.1103565432405427\n",
      "Iteration is: 8, Cost is: 2.1821378738054347\n",
      "Iteration is: 16, Cost is: 1.7133550780898186\n",
      "Iteration is: 32, Cost is: 1.4424555736338986\n",
      "Iteration is: 64, Cost is: 1.3072345222727204\n",
      "Iteration is: 128, Cost is: 1.2468862612954499\n",
      "Iteration is: 256, Cost is: 1.216749107406207\n",
      "Iteration is: 512, Cost is: 1.2123703308353666\n",
      "Iteration is: 1024, Cost is: 1.2116123712948907\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "lam=10\n",
    "w = sgd(X_train_intercept, y_train, max_iterations=2000, stop_criterion=0.001, learning_rate=1e-5, regul_strength=lam, print_outcome=True)\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GQqts4_O1WE"
   },
   "source": [
    "To evaluate the mean accuracy in both train and test set, we write a small function called `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5JahERSXOtJj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9824120603015075\n",
      "Accuracy on test set: 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "def score(w, X, y):\n",
    "  y_preds = np.sign(X @ w)\n",
    "  return np.mean(y_preds == y)\n",
    "\n",
    "print(\"Accuracy on training set: {}\".format(score(w, X_train_intercept, y_train)))\n",
    "print(\"Accuracy on test set: {}\".format(score(w, X_test_intercept, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mz-IlM3mHGv"
   },
   "source": [
    "<a name=\"section-4\"></a>\n",
    "\n",
    "## Section 4: Model Evaluation via *T*-fold Cross Validation\n",
    "\n",
    "Now we repeat the same procedure as above but do not only have one train-test split, but multiple in a *T*-fold cross validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3wk-Bov5K2we"
   },
   "outputs": [],
   "source": [
    "def cross_val_split(N, num_folds):\n",
    "  fold_size = N // num_folds\n",
    "  index_perm = np.random.permutation(np.arange(N))\n",
    "  folds = []\n",
    "  for k in range(num_folds):\n",
    "    folds.append(index_perm[k*fold_size:(k+1)*fold_size])\n",
    "  return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rEkIneWmK-b",
    "outputId": "ff0116d8-e573-46fa-8157-59b06bc75bed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([266, 249,  93,  45, 384, 172,  23, 229, 347,  46, 252, 270, 175,\n",
       "        207, 343,  30,  83,  37, 123, 344, 239, 387,  12, 153, 165,  21,\n",
       "        298, 285,  56, 178, 381, 138, 281, 221,  19, 364, 149,  42, 341,\n",
       "        280,  28, 127, 278, 105, 299, 109,  57, 353, 392, 335, 118, 304,\n",
       "        176,   8,  67, 264, 360, 136, 276, 312, 132, 187, 289, 262,  75,\n",
       "         87,   5, 224, 204, 368,  35, 255,  98, 338, 263, 254, 300, 163,\n",
       "        107]),\n",
       " array([226, 339, 277,  99, 356, 245, 160,  50, 143, 342, 358,  17, 332,\n",
       "        305, 275, 108, 355, 345,  65, 352, 151, 391, 328, 192, 382, 334,\n",
       "         72, 348,  38,  32, 265, 273, 309, 120,  39, 286, 134,  97,  88,\n",
       "        104,   1, 379, 366,  85,  64,  29, 386, 101,  53, 231, 248, 283,\n",
       "         51,  91, 156, 112,  81, 351,  74,  62, 125,  71, 121, 306, 359,\n",
       "         54, 198, 147, 378, 219, 268, 395, 182,   2,  95, 257, 131,  33,\n",
       "        148]),\n",
       " array([324, 201, 144, 329, 116,  58, 110, 233, 367, 314, 191, 111, 159,\n",
       "        146, 318, 369, 235, 220, 161,  92,  94, 349, 327, 164, 389, 279,\n",
       "         47, 103, 193, 157, 215, 206, 308,  43, 260, 139, 169, 274, 227,\n",
       "        170,   0, 195, 135,  90, 196, 184, 315, 331, 237, 377, 133, 370,\n",
       "        269, 246, 129, 244, 251, 209,  48,  20,  78, 174, 228, 330, 326,\n",
       "         66, 261, 346,  52, 225, 340,  34, 166,  82, 267, 311, 284, 114,\n",
       "        186]),\n",
       " array([185, 117,  25, 302, 316,  49, 282, 242, 290, 236,  10,  16, 203,\n",
       "         14, 319, 297, 393,  89,  27,   9,  15, 390, 189, 142, 243, 357,\n",
       "        374, 234, 173, 122,  11, 177, 197, 179, 292, 106, 294,   7, 310,\n",
       "        325, 154, 288, 375,  36, 181, 158,  70, 171, 212,  31, 337, 253,\n",
       "        180, 291, 162, 145,  44,   6, 380, 250,  80,  73, 258, 354, 126,\n",
       "        167,  26, 210,  68, 113, 205,  69, 321, 238, 295, 394, 373, 152,\n",
       "         59]),\n",
       " array([ 40, 385, 396, 155, 137, 232,   4, 217, 388, 336, 202,  13, 213,\n",
       "         96, 199, 200, 350, 361, 214, 256, 102, 372, 218, 230,  77,  41,\n",
       "         76, 397,  84, 183, 115, 208, 140, 211, 100,  86, 128, 259, 333,\n",
       "        168, 240, 320, 194, 287, 313,   3, 150, 323, 271, 130, 362, 241,\n",
       "        247, 272,  79,  24, 188,  55, 119, 317, 301, 223, 363, 307,  60,\n",
       "        293, 190, 376,  63, 222,  18, 303, 383, 322,  22, 216,  61, 365,\n",
       "        296])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "folds = cross_val_split(train.shape[0], 5)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Yjf6Xa-QmK7s"
   },
   "outputs": [],
   "source": [
    "def cross_val_evaluate(data, num_folds):\n",
    "  folds = cross_val_split(data.shape[0], num_folds)\n",
    "\n",
    "  train_scores = []\n",
    "  val_scores = []\n",
    "  \n",
    "  for i in range(len(folds)):\n",
    "    print('Fold', i+1)\n",
    "\n",
    "    val_indices = folds[i]\n",
    "    # define the training set\n",
    "    train_indices = list(set(range(data.shape[0])) - set(val_indices))\n",
    "\n",
    "    X_train = data[train_indices,  :-1]  \n",
    "    y_train = data[train_indices, -1]\n",
    "    \n",
    "    # define the validation set\n",
    "    X_val = data[val_indices,  :-1]  \n",
    "    y_val = data[val_indices, -1]  \n",
    "    \n",
    "    # insert 1 in every row for intercept b\n",
    "    X_train = np.hstack((X_train, np.ones((len(X_train),1)) ))\n",
    "    X_val = np.hstack((X_val, np.ones((len(X_val),1)) ))  \n",
    "\n",
    "    # train the model\n",
    "    w = sgd(X_train, y_train, max_iterations=1025, stop_criterion=0.01, learning_rate=1e-5, regul_strength=1e3)\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "    # evaluate\n",
    "    train_score = score(w, X_train, y_train)\n",
    "    val_score = score(w, X_val, y_val)\n",
    "    print(\"Accuracy on training set #{}: {}\".format(i+1, train_score))\n",
    "    print(\"Accuracy on validation set #{}: {}\".format(i+1, val_score))\n",
    "\n",
    "    train_scores.append(train_score)\n",
    "    val_scores.append(val_score)\n",
    "\n",
    "  return train_scores, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poufUfxFmK47",
    "outputId": "674cbd41-d4d6-4757-f83a-84c10d915a1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training finished.\n",
      "Accuracy on training set #1: 0.987460815047022\n",
      "Accuracy on validation set #1: 0.9873417721518988\n",
      "Fold 2\n",
      "Training finished.\n",
      "Accuracy on training set #2: 0.987460815047022\n",
      "Accuracy on validation set #2: 1.0\n",
      "Fold 3\n",
      "Training finished.\n",
      "Accuracy on training set #3: 0.9937304075235109\n",
      "Accuracy on validation set #3: 0.9367088607594937\n",
      "Fold 4\n",
      "Training finished.\n",
      "Accuracy on training set #4: 0.9968652037617555\n",
      "Accuracy on validation set #4: 0.9620253164556962\n",
      "Fold 5\n",
      "Training finished.\n",
      "Accuracy on training set #5: 0.9905956112852664\n",
      "Accuracy on validation set #5: 0.9620253164556962\n"
     ]
    }
   ],
   "source": [
    "train_scores, val_scores = cross_val_evaluate(train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V8qyYIgmPsk"
   },
   "source": [
    "we compute the mean accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovZTLlNRmJmC",
    "outputId": "73fed2a7-0eb1-4c6a-87f6-a96cda37bbd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9912225705329154 0.969620253164557\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(train_scores), np.mean(val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 4.1: Kernelised SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the follwing, we implement a soft-margin kernelised SVM classifier with a non-linear kernel. Here, we use a Gaussian kernel:\n",
    "$$k(x,y|\\sigma) = e^{-\\frac{||x-y||^2}{\\sigma}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need a function to calculate the kernel given the data #\n",
    "def kernel_matrix(X1,X2,sigma):\n",
    "\n",
    "    n1,m1 = X1.shape\n",
    "    n2,m2 = X2.shape\n",
    "    kernel = np.zeros((n1,n2))\n",
    "\n",
    "    # Here we define a Gaussian Radial Basis Function Kernel #\n",
    "    for i in range(n1):\n",
    "        exponent = np.linalg.norm(X2 - X1[i],axis=1)**2\n",
    "        kernel[i,:] = np.exp(-exponent/sigma) \n",
    "        \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the kernel, we use this to compute the cost below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_kernel(u, K, y, regul_strength=1e3,intercept=0):\n",
    "\n",
    "    # Here I define the hinge cost with the kernel trick. NB: the intercept should be kept separate #\n",
    "    \n",
    "    distances = 1 - (y)*(K@u + intercept) \n",
    "    distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "    hinge = regul_strength * distances.mean()\n",
    "\n",
    "    # calculate cost\n",
    "    return 0.5 * np.dot(u,K@u) + hinge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the lecture notes, the kernel trick can be implemented in the primal-form problem by defining a new loss function:\n",
    "\n",
    "$$L(\\mathbf{u},b) = \\frac{1}{2}\\mathbf{u}^{\\rm{T}}\\mathbf{K} \\mathbf{u} + \\lambda \\sum_{i=1}^N  \\max \\Big\\{0, 1-y^{(i)}(\\mathbf{K}^{(i)}\\mathbf{u} + b)\\Big\\}$$\n",
    "\n",
    "where $\\mathbf{K}$ is the matrix containing the kernel functions, i.e.\n",
    " $\\mathbf{K}_{ij} = k(\\mathbf{x}^{(i)},\\mathbf{x}^{(i)})$. To perform the optimisation, we simply modify the functions introduced above. Note that we will use $X_{\\mathrm{train}}$ and $X_{\\mathrm{test}}$ without the additional vector of ones. We had previously included this vector of ones to learn the intercept term $b$, but within the new formulation, one cannot readily employ this trick. For simplicity, we will drop the intercept by setting $b=0$ here. We are hinting at how you could implement the intercept, but we have deliberately left out a few lines of code for you to work on in the course work (2023).\n",
    " \n",
    "Following the steps above, we want to optimize the cost is by using SGD. First, we thus create a function that computes the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost_gradient_kernel(u, K_batch, y_batch, regul_strength=1e3,intercept=0):\n",
    "\n",
    "    # if only one example is passed\n",
    "    if type(y_batch) == np.float64 or type(y_batch) == np.int32:\n",
    "        y_batch = np.asarray([y_batch])\n",
    "        K_batch = np.asarray([K_batch])  # gives multidimensional array\n",
    "    \n",
    "    distance = 1 - (y_batch * (K_batch @ u + intercept)) \n",
    "    dw = np.zeros(len(u))\n",
    "\n",
    "    # define the gradient with the hinge loss #\n",
    "    for ind, d in enumerate(distance):\n",
    "        if max(0, d)==0:\n",
    "            di = K_batch@u \n",
    "        else:\n",
    "            di = K_batch@u - (regul_strength * y_batch[ind] * K_batch[ind]) \n",
    "        dw += di\n",
    "\n",
    "    return dw/len(y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the functions above in SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_kernel(K, y, batch_size=32, max_iterations=4000, stop_criterion=0.001, learning_rate=1e-4, regul_strength=1e3, print_outcome=False):\n",
    "\n",
    "    # initialise zero u and intercept\n",
    "    u = np.zeros(K.shape[1])\n",
    "    intercept=0\n",
    "    \n",
    "    nth = 0\n",
    "    # initialise starting cost as infinity\n",
    "    prev_cost = np.inf\n",
    "    \n",
    "    # stochastic gradient descent\n",
    "    indices = np.arange(len(y))\n",
    "    for iteration in range(1, max_iterations):\n",
    "        # shuffle to prevent repeating update cycles\n",
    "        np.random.shuffle(indices)\n",
    "        batch_idx = indices[:batch_size]\n",
    "        K_b, y_b = K[batch_idx], y[batch_idx]\n",
    "        for ki, yi in zip(K_b, y_b):\n",
    "            ascent = calculate_cost_gradient_kernel(u, ki, yi, regul_strength, intercept) \n",
    "            u = u - (learning_rate * ascent)\n",
    "        \n",
    "        # convergence check on 2^n'th iteration\n",
    "        if iteration==2**nth or iteration==max_iterations-1:\n",
    "            # compute cost\n",
    "            cost = compute_cost_kernel(u, K, y, regul_strength, intercept)\n",
    "            if print_outcome:\n",
    "                print(\"Iteration is: {}, Cost is: {}\".format(iteration, cost))\n",
    "            # stop criterion\n",
    "            if abs(prev_cost - cost) < stop_criterion * prev_cost:\n",
    "                return u, intercept\n",
    "            \n",
    "            prev_cost = cost\n",
    "            nth += 1\n",
    "    \n",
    "    return u, intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's fix the regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sigma = 1\n",
      "Accuracy on training set: 1.0\n",
      "Accuracy on test set: 0.9649122807017544\n",
      "For sigma = 2\n",
      "Accuracy on training set: 1.0\n",
      "Accuracy on test set: 0.9707602339181286\n",
      "For sigma = 5\n",
      "Accuracy on training set: 0.9974874371859297\n",
      "Accuracy on test set: 0.9766081871345029\n",
      "For sigma = 10\n",
      "Accuracy on training set: 0.9974874371859297\n",
      "Accuracy on test set: 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "reg=1\n",
    "for sigma in [1,2,5,10]:\n",
    "    \n",
    "    print('For sigma = ' + str(sigma))\n",
    "    K_train = kernel_matrix(X_train,X_train, sigma)\n",
    "\n",
    "    u,b = sgd_kernel(K_train, y_train, batch_size=128, max_iterations=2000, stop_criterion=0.001, learning_rate=1e-5, regul_strength=1e3, print_outcome=False)\n",
    "\n",
    "    def score(u, X, y, sigma, intercept):\n",
    "        ## now I define the kernel containing test and train data ##\n",
    "        K_test = kernel_matrix(X,X_train, sigma)\n",
    "        \n",
    "        ## The \n",
    "        y_preds = np.sign(K_test@u + intercept)\n",
    "        \n",
    "        return np.mean(y_preds == y) \n",
    "\n",
    "    print(\"Accuracy on training set: {}\".format(score(u, X_train, y_train, sigma, b)))\n",
    "    print(\"Accuracy on test set: {}\".format(score(u, X_test, y_test, sigma, b)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[Solved] SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
