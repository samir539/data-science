{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY98Oclcl92-"
      },
      "source": [
        "# Naive Bayes\n",
        "\n",
        "Naive Bayes is a classification algorithm based on Bayes' theorem. Bayesâ€™ theorem provides a way to calculate the probability of a data point belonging to a given class, given our prior knowledge. It is defined as\n",
        "\n",
        "$$\n",
        "\\mathbb P (class|data) = \\frac{\\mathbb P (data|class) \\ \\mathbb P (class)}{\\mathbb P (data)} ,\n",
        "$$\n",
        "\n",
        "where $\\mathbb P (class | data)$ is the probability over the potential classes given the provided data. The different probabilities $\\mathbb P$ you see in the equations above are commonly called prior, likelihood, evidence, and posterior as follows.\n",
        "\n",
        "$$\n",
        "\\overbrace{\\mathbb P (class|data)}^{\\text{posterior}} = \\frac{\\overbrace{\\mathbb P (data|class)}^{\\text{likelihood}} \\ \\overbrace{\\mathbb P (class)}^{\\text{prior}}}{\\underbrace{\\mathbb P (data)}_{\\text{evidence}}}\n",
        "$$\n",
        "\n",
        "The algorithm is 'naive', because of its assumption that features of data are independent given the class label. Let us call the data features $x_1, \\dots, x_i, \\dots, x_n$ and the class label $y$, and rewrite Bayes theorem in these terms:\n",
        "\n",
        "$$\n",
        "\\mathbb P (y|x_1, \\dots, x_n) = \\frac{\\mathbb P (x_1, \\dots, x_n|y) * \\mathbb P (y)}{\\mathbb P (x_1, \\dots, x_n)} \\, . \n",
        "$$\n",
        "\n",
        "Then, the naive assumption of conditional independence between any two features given the class label can be expressed as\n",
        "\n",
        "$$\n",
        "\\mathbb P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n) = \\mathbb P (x_i | y) \\, .\n",
        "$$\n",
        "\n",
        "For all $i$, we can simply Bayes' theorem to:\n",
        "\n",
        "$$\n",
        "\\mathbb P (y | x_1, \\dots, x_n) = \\frac{\\mathbb P (y) \\prod_{i=1}^n \\mathbb P(x_i | y)}{\\mathbb P (x_1, \\dots, x_n)} \\, .\n",
        "$$\n",
        "\n",
        "Since $\\mathbb P (x_1, \\dots, x_n)$ is the constant input, we can define the following proportional relationship\n",
        "\n",
        "$$\n",
        "\\mathbb P (y|x_1, \\dots, x_n) \\propto \\mathbb P (y) \\prod_{i=1}^n \\mathbb P(x_i | y) \\, ,\n",
        "$$\n",
        "\n",
        "and can use it to classify any data point as\n",
        "\n",
        "$$\n",
        "\\hat y = \\underset{y}{\\text{arg max}} \\ \\mathbb P (y) \\prod_{i=1}^n \\mathbb P(x_i | y) \\, .\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8r_Xo0HklZFx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Callable\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.utils.validation import check_X_y, check_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wbwhd07rsZxv"
      },
      "outputs": [],
      "source": [
        "def make_spam_dataset(show_X=True):\n",
        "    \"\"\" Create a small toy dataset for MultinomialNB implementation\n",
        "    \n",
        "    Returns:\n",
        "        X: word count matrix\n",
        "        y: indicator of whether or not message is spam\n",
        "        msg_tx_func: a function to transform new test data into word count matrix\n",
        "    \"\"\"\n",
        "\n",
        "    vocab = [\n",
        "        'secret', 'offer', 'low', 'price', 'valued', 'customer', 'today',\n",
        "        'dollar', 'million', 'sports', 'is', 'for', 'play', 'healthy', 'pizza'\n",
        "    ]\n",
        "\n",
        "    spam = [\n",
        "        'million dollar offer',\n",
        "        'secret offer today',\n",
        "        'secret is secret'\n",
        "    ]\n",
        "    \n",
        "    not_spam = [\n",
        "        'low price for valued customer',\n",
        "        'play secret sports today',\n",
        "        'sports is healthy',\n",
        "        'low price pizza'\n",
        "    ]\n",
        "\n",
        "    all_messages = spam + not_spam\n",
        "    \n",
        "    vectorizer = CountVectorizer(vocabulary=vocab)\n",
        "    word_counts = vectorizer.fit_transform(all_messages).toarray()\n",
        "    df = pd.DataFrame(word_counts, columns=vocab)\n",
        "    is_spam = [1] * len(spam) + [0] * len(not_spam)  # storing our labels in a list (1 means spam email, 0 means no spam email)\n",
        "    msg_tx_func = lambda x: vectorizer.transform(x).toarray()\n",
        "    \n",
        "    if show_X:\n",
        "        display(df)\n",
        "        \n",
        "    return df.to_numpy(), np.array(is_spam), msg_tx_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "LAF17qr2sv9G",
        "outputId": "b987797d-fc28-4c7b-a3b4-670460300e3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>secret</th>\n",
              "      <th>offer</th>\n",
              "      <th>low</th>\n",
              "      <th>price</th>\n",
              "      <th>valued</th>\n",
              "      <th>customer</th>\n",
              "      <th>today</th>\n",
              "      <th>dollar</th>\n",
              "      <th>million</th>\n",
              "      <th>sports</th>\n",
              "      <th>is</th>\n",
              "      <th>for</th>\n",
              "      <th>play</th>\n",
              "      <th>healthy</th>\n",
              "      <th>pizza</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   secret  offer  low  price  valued  customer  today  dollar  million  \\\n",
              "0       0      1    0      0       0         0      0       1        1   \n",
              "1       1      1    0      0       0         0      1       0        0   \n",
              "2       2      0    0      0       0         0      0       0        0   \n",
              "3       0      0    1      1       1         1      0       0        0   \n",
              "4       1      0    0      0       0         0      1       0        0   \n",
              "5       0      0    0      0       0         0      0       0        0   \n",
              "6       0      0    1      1       0         0      0       0        0   \n",
              "\n",
              "   sports  is  for  play  healthy  pizza  \n",
              "0       0   0    0     0        0      0  \n",
              "1       0   0    0     0        0      0  \n",
              "2       0   1    0     0        0      0  \n",
              "3       0   0    1     0        0      0  \n",
              "4       1   0    0     1        0      0  \n",
              "5       1   1    0     0        1      0  \n",
              "6       0   0    0     0        0      1  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# define our variables and print X\n",
        "X, y, tx_func = make_spam_dataset(show_X=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKlchW7Eswez",
        "outputId": "808214a2-a3c2-4bcd-ef57-8498c84f3075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# see how y looks like\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KReuBEwe1hye"
      },
      "source": [
        "Next, we train the Naive Bayes classifier with a `train` function where we define the prior.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aq5Bwv4h1hZk"
      },
      "outputs": [],
      "source": [
        "def train(X, y):\n",
        "  \"\"\" Use training data for Naive Bayes classifier \"\"\"\n",
        "\n",
        "  # not strictly necessary, but this ensures we have clean input\n",
        "  X, y = check_X_y(X, y)\n",
        "  n = X.shape[0]\n",
        "\n",
        "  # reorder X as a 2-dimensional array; each dimension contains data examples of only one of our two classes\n",
        "  X_by_class = np.array([X[y==c] for c in np.unique(y)])\n",
        "  # define prior\n",
        "  prior = np.array([len(X_class) / n for X_class in X_by_class]) ## <-- SOLUTION\n",
        "\n",
        "  # count words in each class\n",
        "  word_counts = np.array([sub_arr.sum(axis=0) for sub_arr in X_by_class])\n",
        "  # define likelihood\n",
        "  lk_word = word_counts / word_counts.sum(axis=1).reshape(-1, 1)\n",
        "\n",
        "  return prior, lk_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0A0YJje7rup",
        "outputId": "c6cc8dd4-c874-4c6b-ac6b-4755857bfa58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prior: [0.57142857 0.42857143]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\44746\\AppData\\Local\\Temp\\ipykernel_31452\\1514464344.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_by_class = np.array([X[y==c] for c in np.unique(y)])\n"
          ]
        }
      ],
      "source": [
        "# call function and print prior\n",
        "prior, lk_word = train(X, y)\n",
        "print('Prior:', prior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EYrQ6cx91hSA"
      },
      "outputs": [],
      "source": [
        "def predict_proba(X, y):\n",
        "  \"\"\" Predict probability of class \"\"\"\n",
        "\n",
        "  X = check_array(X)\n",
        "  print(X.shape)\n",
        "  X, y = check_X_y(X, y)\n",
        "\n",
        "  # insert train function within this function\n",
        "  prior, lk_word = train(X, y)\n",
        "\n",
        "  # loop over each observation to calculate conditional probabilities\n",
        "  class_numerators = np.zeros(shape=(X.shape[0], prior.shape[0]))\n",
        "  for i, x in enumerate(X):\n",
        "    \n",
        "    # count how often words appear in each email\n",
        "    word_exists = x.astype(bool)\n",
        "    #print(word_exists)\n",
        "    \n",
        "    # compute likelihoods of words (probability of data appearing in any class)\n",
        "    lk_words_present = lk_word[:, word_exists] ** x[word_exists]\n",
        "    #print(lk_words_present)\n",
        "    \n",
        "    # compute likelihood of entire message with likelihoods of words\n",
        "    lk_message = (lk_words_present).prod(axis=1)\n",
        "    #print(lk_message)\n",
        "    \n",
        "    # combine likelihood and prior to numerator\n",
        "    class_numerators[i] = lk_message * prior \n",
        "\n",
        "  normalize_term = class_numerators.sum(axis=1).reshape(-1, 1)\n",
        "  print(normalize_term)\n",
        "  posteriors = class_numerators / normalize_term\n",
        "  \n",
        "  return posteriors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ViH8LlA1hNn",
        "outputId": "f753d2d9-ffac-4e3a-e5aa-95b2599528b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 15)\n",
            "[[1.17577895e-03]\n",
            " [3.52733686e-03]\n",
            " [5.46031746e-03]\n",
            " [3.00999412e-06]\n",
            " [2.25749559e-05]\n",
            " [3.38624339e-04]\n",
            " [6.77248677e-04]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\44746\\AppData\\Local\\Temp\\ipykernel_31452\\1514464344.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_by_class = np.array([X[y==c] for c in np.unique(y)])\n"
          ]
        }
      ],
      "source": [
        "posteriors = predict_proba(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUJxJ9h6C4g_"
      },
      "source": [
        "Now, we can predict in a binary fashion by asserting any data points to the class with the highest probability. Here, we take our emails we trained our Naive Bayes classifier on also to evaluate it, but the evaluation normally happens on unseen emails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "36IsDfzH1eXN"
      },
      "outputs": [],
      "source": [
        "def predict(X, y):\n",
        "  \"\"\" Predict class with highest probability \"\"\"\n",
        "  return predict_proba(X, y).argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FroLvChb1hKg",
        "outputId": "1c45a9a1-f772-48b6-b4a6-6e03a68935dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 15)\n",
            "[[1.17577895e-03]\n",
            " [3.52733686e-03]\n",
            " [5.46031746e-03]\n",
            " [3.00999412e-06]\n",
            " [2.25749559e-05]\n",
            " [3.38624339e-04]\n",
            " [6.77248677e-04]]\n",
            "[1 1 1 0 0 0 0]\n",
            "Accuracy: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\44746\\AppData\\Local\\Temp\\ipykernel_31452\\1514464344.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_by_class = np.array([X[y==c] for c in np.unique(y)])\n"
          ]
        }
      ],
      "source": [
        "preds = predict(X, y)\n",
        "print(preds)\n",
        "print(f'Accuracy: {(preds==y).mean()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NbFBjsD71ee6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Smp9IiWMzzbv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "[Solved] Naive_Bayes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
